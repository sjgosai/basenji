{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, subprocess\n",
    "from IPython.display import IFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precursors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train a model, you first need to convert your sequences and targets into the input HDF5 format. Check out my tutorials for how to do that; they're linked from the [main page](../README.md).\n",
    "\n",
    "For this tutorial, grab a small example HDF5 that I constructed here with 10% of the training sequences and only GM12878 targets for various DNase-seq, ChIP-seq, and CAGE experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.isfile('data/heart_l131k.h5'):\n",
    "    subprocess.call('curl -o data/heart_l131k.h5 https://storage.googleapis.com/basenji_tutorial_data/heart_l131k.h5', shell=True)\n",
    "    subprocess.call('curl -o data/heart_l131k.bed https://storage.googleapis.com/basenji_tutorial_data/heart_l131k.bed', shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you need to decide what sort of architecture to use. This grammar probably needs work; my goal was to enable hyperparameter searches to write the parameters to file so that I could run parallel training jobs to explore the hyperparameter space. I included an example set of parameters that will work well with this data in models/params_small.txt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, run [basenji_train.py](https://github.com/calico/basenji/blob/master/bin/basenji_train.py) to train a model. The program will offer training feedback via stdout and write the model output files to the prefix given by the *-s* parameter.\n",
    "\n",
    "The most relevant options here are:\n",
    "\n",
    "| Option/Argument | Value | Note |\n",
    "|:---|:---|:---|\n",
    "| --augment_rc | True | Process even-numbered epochs as forward, odd-numbered as reverse complemented. |\n",
    "| --ensemble_rc | True | Average forward and reverse complemented predictions on validation set. |\n",
    "| --augment_shifts | \"1,0,-1\" | Rotate epochs over small sequence shifts. |\n",
    "| --logdir | models/heart | Directory to save training logs and model checkpoints. |\n",
    "| --params | models/params_small.txt | Table of parameters to setup the model architecture and optimization. |\n",
    "| --data | data/heart_l131k.h5 | HDF5 file containing the training and validation input and output datasets as generated by [basenji_hdf5_single.py](https://github.com/calico/basenji/blob/master/bin/basenji_hdf5_single.py) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to train, uncomment the following line and run it. Depending on your hardware, it may require several hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 4, 'batch_buffer': 4096, 'link': 'softplus', 'loss': 'poisson', 'optimizer': 'adam', 'adam_beta1': 0.97, 'adam_beta2': 0.98, 'learning_rate': 0.002, 'num_targets': 3, 'target_pool': 128, 'seq_length': 131072, 'target_length': 1024, 'cnn_dropout': 0.1, 'cnn_filter_sizes': [20, 7, 7, 7, 3, 3, 3, 3, 3, 3, 3, 1], 'cnn_filters': [128, 128, 192, 256, 256, 32, 32, 32, 32, 32, 32, 384], 'cnn_pool': [2, 4, 4, 4, 1, 0, 0, 0, 0, 0, 0, 0], 'cnn_dilation': [1, 1, 1, 1, 1, 2, 4, 8, 16, 32, 64, 1], 'cnn_dense': [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0]}\n",
      "Cannot order TFRecords data/heart_l131k/tfrecords/train-0.tfr\n",
      "Cannot order TFRecords data/heart_l131k/tfrecords/valid-0.tfr\n",
      "Targets pooled by 128 to length 1024\n",
      "Convolution w/ 3 384x1 filters to final targets\n",
      "Targets pooled by 128 to length 1024\n",
      "Convolution w/ 3 384x1 filters to final targets\n",
      "2018-12-30 10:03:17.832014: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "WARNING:tensorflow:From /Users/davidkelley/code/Basenji/bin/basenji_train.py:79: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:`tf.train.start_queue_runners()` was called when no queue runners were defined. You can safely remove the call to this deprecated function.\n",
      "Initializing...\n",
      "Initialization time 0.534710\n",
      "Epoch:   1,  Steps:      64,  Train loss: 0.54798,  Valid loss: 0.50837,  Valid R2: 0.11809,  Valid R: 0.40257, Time:  11m, best!\n",
      "Epoch:   2,  Steps:     128,  Train loss: 0.46754,  Valid loss: 0.45296,  Valid R2: 0.19501,  Valid R: 0.44902, Time:  11m, best!\n",
      "Epoch:   3,  Steps:     192,  Train loss: 0.45048,  Valid loss: 0.44605,  Valid R2: 0.19979,  Valid R: 0.47541, Time:  12m, best!\n",
      "Epoch:   4,  Steps:     256,  Train loss: 0.44168,  Valid loss: 0.57095,  Valid R2: 0.12694,  Valid R: 0.44942, Time:  11m\n",
      "Epoch:   5,  Steps:     320,  Train loss: 0.43908,  Valid loss: 0.69980,  Valid R2: -0.04671,  Valid R: 0.42801, Time:  11m\n",
      "Epoch:   6,  Steps:     384,  Train loss: 0.43399,  Valid loss: 0.42879,  Valid R2: 0.24579,  Valid R: 0.56198, Time:  11m, best!\n",
      "Epoch:   7,  Steps:     448,  Train loss: 0.42770,  Valid loss: 0.59498,  Valid R2: 0.07055,  Valid R: 0.46932, Time:  11m\n",
      "Epoch:   8,  Steps:     512,  Train loss: 0.42783,  Valid loss: 0.48429,  Valid R2: 0.27783,  Valid R: 0.56532, Time:  10m\n",
      "Epoch:   9,  Steps:     576,  Train loss: 0.41828,  Valid loss: 0.50970,  Valid R2: 0.29550,  Valid R: 0.59658, Time:  11m\n",
      "Epoch:  10,  Steps:     640,  Train loss: 0.41579,  Valid loss: 0.42198,  Valid R2: 0.27749,  Valid R: 0.66673, Time:  10m, best!\n",
      "Epoch:  11,  Steps:     704,  Train loss: 0.41278,  Valid loss: 0.57969,  Valid R2: 0.19935,  Valid R: 0.57276, Time:  11m\n",
      "Epoch:  12,  Steps:     768,  Train loss: 0.40908,  Valid loss: 0.61094,  Valid R2: 0.24059,  Valid R: 0.63982, Time:  11m\n",
      "Epoch:  13,  Steps:     832,  Train loss: 0.40099,  Valid loss: 0.53835,  Valid R2: 0.37713,  Valid R: 0.71957, Time: 1.7h\n",
      "Epoch:  14,  Steps:     896,  Train loss: 0.39827,  Valid loss: 0.54155,  Valid R2: 0.35786,  Valid R: 0.72741, Time:  46m\n",
      "Epoch:  15,  Steps:     960,  Train loss: 0.39597,  Valid loss: 0.45066,  Valid R2: 0.31514,  Valid R: 0.71939, Time:  10m\n",
      "Epoch:  16,  Steps:    1024,  Train loss: 0.39644,  Valid loss: 0.39112,  Valid R2: 0.50388,  Valid R: 0.77973, Time:  11m, best!\n",
      "Epoch:  17,  Steps:    1088,  Train loss: 0.39389,  Valid loss: 0.42965,  Valid R2: 0.37235,  Valid R: 0.77539, Time:  10m\n",
      "Epoch:  18,  Steps:    1152,  Train loss: 0.38921,  Valid loss: 0.45896,  Valid R2: 0.52484,  Valid R: 0.79395, Time:  11m\n",
      "Epoch:  19,  Steps:    1216,  Train loss: 0.38732,  Valid loss: 0.43870,  Valid R2: 0.54886,  Valid R: 0.79862, Time:  11m\n",
      "Epoch:  20,  Steps:    1280,  Train loss: 0.38292,  Valid loss: 1.39013,  Valid R2: -1.45267,  Valid R: 0.53996, Time:  11m\n",
      "Epoch:  21,  Steps:    1344,  Train loss: 0.37988,  Valid loss: 0.40977,  Valid R2: 0.54512,  Valid R: 0.81684, Time:  14m\n",
      "Epoch:  22,  Steps:    1408,  Train loss: 0.38031,  Valid loss: 0.39191,  Valid R2: 0.55077,  Valid R: 0.82903, Time:  15m\n",
      "Epoch:  23,  Steps:    1472,  Train loss: 0.37766,  Valid loss: 0.40836,  Valid R2: 0.65285,  Valid R: 0.83572, Time:  10m\n",
      "Epoch:  24,  Steps:    1536,  Train loss: 0.37701,  Valid loss: 0.37189,  Valid R2: 0.64141,  Valid R: 0.85175, Time:  10m, best!\n",
      "Epoch:  25,  Steps:    1600,  Train loss: 0.37239,  Valid loss: 0.37260,  Valid R2: 0.63724,  Valid R: 0.85301, Time:  12m\n",
      "Epoch:  26,  Steps:    1664,  Train loss: 0.37034,  Valid loss: 0.43513,  Valid R2: 0.54498,  Valid R: 0.83185, Time:  16m\n",
      "Epoch:  27,  Steps:    1728,  Train loss: 0.36619,  Valid loss: 0.38212,  Valid R2: 0.64360,  Valid R: 0.85545, Time:  11m\n",
      "Epoch:  28,  Steps:    1792,  Train loss: 0.36528,  Valid loss: 0.42481,  Valid R2: 0.63249,  Valid R: 0.84824, Time:  10m\n",
      "Epoch:  29,  Steps:    1856,  Train loss: 0.36741,  Valid loss: 0.39385,  Valid R2: 0.55433,  Valid R: 0.84878, Time:  10m\n",
      "Epoch:  30,  Steps:    1920,  Train loss: 0.36575,  Valid loss: 0.36491,  Valid R2: 0.63219,  Valid R: 0.86865, Time:  10m, best!\n",
      "Epoch:  31,  Steps:    1984,  Train loss: 0.36719,  Valid loss: 0.36997,  Valid R2: 0.59580,  Valid R: 0.86431, Time:  10m\n",
      "Epoch:  32,  Steps:    2048,  Train loss: 0.36380,  Valid loss: 2.08366,  Valid R2: -4.29759,  Valid R: 0.53922, Time:  10m\n",
      "Epoch:  33,  Steps:    2112,  Train loss: 0.36198,  Valid loss: 0.37642,  Valid R2: 0.62026,  Valid R: 0.86578, Time:  10m\n",
      "Epoch:  34,  Steps:    2176,  Train loss: 0.36166,  Valid loss: 0.52086,  Valid R2: 0.58701,  Valid R: 0.82915, Time:  10m\n",
      "Epoch:  35,  Steps:    2240,  Train loss: 0.36086,  Valid loss: 0.42367,  Valid R2: 0.67428,  Valid R: 0.85999, Time:  10m\n",
      "Epoch:  36,  Steps:    2304,  Train loss: 0.35806,  Valid loss: 0.34984,  Valid R2: 0.73613,  Valid R: 0.87698, Time:  10m, best!\n",
      "Epoch:  37,  Steps:    2368,  Train loss: 0.35560,  Valid loss: 0.52897,  Valid R2: 0.56757,  Valid R: 0.82621, Time:  10m\n",
      "Epoch:  38,  Steps:    2432,  Train loss: 0.35761,  Valid loss: 0.35334,  Valid R2: 0.74278,  Valid R: 0.87334, Time:  10m\n",
      "Epoch:  39,  Steps:    2496,  Train loss: 0.35448,  Valid loss: 0.36375,  Valid R2: 0.65299,  Valid R: 0.88278, Time:  10m\n",
      "Epoch:  40,  Steps:    2560,  Train loss: 0.35670,  Valid loss: 0.46232,  Valid R2: 0.62653,  Valid R: 0.82832, Time:  11m\n",
      "Epoch:  41,  Steps:    2624,  Train loss: 0.35466,  Valid loss: 0.35978,  Valid R2: 0.67159,  Valid R: 0.88454, Time:  16m\n",
      "Epoch:  42,  Steps:    2688,  Train loss: 0.35332,  Valid loss: 0.36449,  Valid R2: 0.75558,  Valid R: 0.88491, Time:  12m\n",
      "Epoch:  43,  Steps:    2752,  Train loss: 0.35067,  Valid loss: 0.36303,  Valid R2: 0.70350,  Valid R: 0.88669, Time:  12m\n",
      "Epoch:  44,  Steps:    2816,  Train loss: 0.35019,  Valid loss: 0.35747,  Valid R2: 0.73664,  Valid R: 0.88689, Time:  12m\n",
      "Epoch:  45,  Steps:    2880,  Train loss: 0.34723,  Valid loss: 0.35093,  Valid R2: 0.75646,  Valid R: 0.88575, Time:  12m\n",
      "Epoch:  46,  Steps:    2944,  Train loss: 0.34751,  Valid loss: 0.35941,  Valid R2: 0.74059,  Valid R: 0.88456, Time:  12m\n",
      "Epoch:  47,  Steps:    3008,  Train loss: 0.34653,  Valid loss: 0.36225,  Valid R2: 0.67027,  Valid R: 0.88959, Time:  12m\n",
      "Epoch:  48,  Steps:    3072,  Train loss: 0.34726,  Valid loss: 0.34389,  Valid R2: 0.73502,  Valid R: 0.89121, Time:  12m, best!\n",
      "Epoch:  49,  Steps:    3136,  Train loss: 0.34518,  Valid loss: 0.42555,  Valid R2: 0.72029,  Valid R: 0.88178, Time:  12m\n",
      "Epoch:  50,  Steps:    3200,  Train loss: 0.34378,  Valid loss: 0.38062,  Valid R2: 0.71768,  Valid R: 0.88494, Time:  12m\n",
      "Epoch:  51,  Steps:    3264,  Train loss: 0.34390,  Valid loss: 0.33910,  Valid R2: 0.77769,  Valid R: 0.89730, Time:  12m, best!\n",
      "Epoch:  52,  Steps:    3328,  Train loss: 0.34509,  Valid loss: 0.35723,  Valid R2: 0.70051,  Valid R: 0.88829, Time:  12m\n",
      "Epoch:  53,  Steps:    3392,  Train loss: 0.34144,  Valid loss: 0.33772,  Valid R2: 0.79992,  Valid R: 0.90234, Time:  12m, best!\n",
      "Epoch:  54,  Steps:    3456,  Train loss: 0.33926,  Valid loss: 0.33647,  Valid R2: 0.78851,  Valid R: 0.90718, Time:  12m, best!\n",
      "Epoch:  55,  Steps:    3520,  Train loss: 0.33909,  Valid loss: 0.34211,  Valid R2: 0.78600,  Valid R: 0.90505, Time:  12m\n",
      "Epoch:  56,  Steps:    3584,  Train loss: 0.34006,  Valid loss: 0.33991,  Valid R2: 0.78316,  Valid R: 0.89056, Time:  12m\n",
      "Epoch:  57,  Steps:    3648,  Train loss: 0.33956,  Valid loss: 0.35222,  Valid R2: 0.77130,  Valid R: 0.89373, Time:  12m\n",
      "Epoch:  58,  Steps:    3712,  Train loss: 0.33900,  Valid loss: 0.33975,  Valid R2: 0.78289,  Valid R: 0.90995, Time:  12m\n",
      "Epoch:  59,  Steps:    3776,  Train loss: 0.33684,  Valid loss: 0.33306,  Valid R2: 0.79552,  Valid R: 0.90815, Time:  12m, best!\n",
      "Epoch:  60,  Steps:    3840,  Train loss: 0.33542,  Valid loss: 0.33213,  Valid R2: 0.76951,  Valid R: 0.90966, Time:  12m, best!\n",
      "Epoch:  61,  Steps:    3904,  Train loss: 0.33416,  Valid loss: 0.33201,  Valid R2: 0.79442,  Valid R: 0.91495, Time:  12m, best!\n",
      "Epoch:  62,  Steps:    3968,  Train loss: 0.33552,  Valid loss: 0.33828,  Valid R2: 0.74674,  Valid R: 0.91039, Time:  12m\n",
      "Epoch:  63,  Steps:    4032,  Train loss: 0.33248,  Valid loss: 0.32667,  Valid R2: 0.80231,  Valid R: 0.90697, Time:  96m, best!\n",
      "Epoch:  64,  Steps:    4096,  Train loss: 0.33235,  Valid loss: 0.33987,  Valid R2: 0.73492,  Valid R: 0.91442, Time: 1.8h\n",
      "Epoch:  65,  Steps:    4160,  Train loss: 0.33064,  Valid loss: 0.32606,  Valid R2: 0.80529,  Valid R: 0.91951, Time:  77m, best!\n",
      "Epoch:  66,  Steps:    4224,  Train loss: 0.33150,  Valid loss: 0.33539,  Valid R2: 0.78229,  Valid R: 0.91526, Time: 1.7h\n",
      "Epoch:  67,  Steps:    4288,  Train loss: 0.33029,  Valid loss: 0.32660,  Valid R2: 0.81201,  Valid R: 0.91546, Time: 2.3h\n",
      "Epoch:  68,  Steps:    4352,  Train loss: 0.32882,  Valid loss: 0.34101,  Valid R2: 0.76512,  Valid R: 0.90739, Time:  12m\n",
      "Epoch:  69,  Steps:    4416,  Train loss: 0.32945,  Valid loss: 0.32422,  Valid R2: 0.79344,  Valid R: 0.92403, Time:  12m, best!\n",
      "Epoch:  70,  Steps:    4480,  Train loss: 0.32740,  Valid loss: 0.34341,  Valid R2: 0.77269,  Valid R: 0.91690, Time:  12m\n",
      "Epoch:  71,  Steps:    4544,  Train loss: 0.32754,  Valid loss: 0.34025,  Valid R2: 0.77227,  Valid R: 0.90872, Time:  11m\n",
      "Epoch:  72,  Steps:    4608,  Train loss: 0.32648,  Valid loss: 0.32635,  Valid R2: 0.80820,  Valid R: 0.92423, Time:  14m\n",
      "Epoch:  73,  Steps:    4672,  Train loss: 0.32643,  Valid loss: 0.32839,  Valid R2: 0.77027,  Valid R: 0.92325, Time:  12m\n",
      "Epoch:  74,  Steps:    4736,  Train loss: 0.32498,  Valid loss: 0.32502,  Valid R2: 0.81572,  Valid R: 0.92363, Time:  13m\n",
      "Epoch:  75,  Steps:    4800,  Train loss: 0.32677,  Valid loss: 0.32351,  Valid R2: 0.79039,  Valid R: 0.92623, Time:  13m, best!\n",
      "Epoch:  76,  Steps:    4864,  Train loss: 0.32423,  Valid loss: 0.31421,  Valid R2: 0.81770,  Valid R: 0.92119, Time:  10m, best!\n",
      "Epoch:  77,  Steps:    4928,  Train loss: 0.32333,  Valid loss: 0.32335,  Valid R2: 0.81276,  Valid R: 0.92582, Time:  10m\n",
      "Epoch:  78,  Steps:    4992,  Train loss: 0.32365,  Valid loss: 0.32141,  Valid R2: 0.81214,  Valid R: 0.92849, Time:  10m\n",
      "Epoch:  79,  Steps:    5056,  Train loss: 0.32257,  Valid loss: 0.34109,  Valid R2: 0.76533,  Valid R: 0.92229, Time:  11m\n",
      "Epoch:  80,  Steps:    5120,  Train loss: 0.32150,  Valid loss: 0.31964,  Valid R2: 0.79151,  Valid R: 0.92981, Time:  10m\n",
      "Epoch:  81,  Steps:    5184,  Train loss: 0.31984,  Valid loss: 0.32018,  Valid R2: 0.79939,  Valid R: 0.92778, Time:  10m\n",
      "Epoch:  82,  Steps:    5248,  Train loss: 0.32047,  Valid loss: 0.31183,  Valid R2: 0.82695,  Valid R: 0.93240, Time:  10m, best!\n",
      "Epoch:  83,  Steps:    5312,  Train loss: 0.31985,  Valid loss: 0.32654,  Valid R2: 0.81900,  Valid R: 0.92885, Time:  12m\n",
      "Epoch:  84,  Steps:    5376,  Train loss: 0.31875,  Valid loss: 0.31457,  Valid R2: 0.82194,  Valid R: 0.92636, Time:  18m\n",
      "Epoch:  85,  Steps:    5440,  Train loss: 0.31830,  Valid loss: 0.31658,  Valid R2: 0.81041,  Valid R: 0.92741, Time:  12m\n",
      "Epoch:  86,  Steps:    5504,  Train loss: 0.31814,  Valid loss: 0.30960,  Valid R2: 0.85137,  Valid R: 0.92969, Time:  13m, best!\n",
      "Epoch:  87,  Steps:    5568,  Train loss: 0.31993,  Valid loss: 0.30976,  Valid R2: 0.84653,  Valid R: 0.93234, Time:  12m\n",
      "Epoch:  88,  Steps:    5632,  Train loss: 0.31840,  Valid loss: 0.31283,  Valid R2: 0.81812,  Valid R: 0.93274, Time: 2.2h\n",
      "Epoch:  89,  Steps:    5696,  Train loss: 0.31700,  Valid loss: 0.31150,  Valid R2: 0.84518,  Valid R: 0.93837, Time: 1.8h\n",
      "Epoch:  90,  Steps:    5760,  Train loss: 0.31681,  Valid loss: 0.30936,  Valid R2: 0.84419,  Valid R: 0.93288, Time:  59m, best!\n",
      "Epoch:  91,  Steps:    5824,  Train loss: 0.31719,  Valid loss: 0.32329,  Valid R2: 0.80486,  Valid R: 0.91987, Time: 2.6h\n",
      "Epoch:  92,  Steps:    5888,  Train loss: 0.31572,  Valid loss: 0.30792,  Valid R2: 0.82853,  Valid R: 0.93474, Time:  10m, best!\n",
      "Epoch:  93,  Steps:    5952,  Train loss: 0.31513,  Valid loss: 0.30492,  Valid R2: 0.83247,  Valid R: 0.93957, Time:  10m, best!\n",
      "Epoch:  94,  Steps:    6016,  Train loss: 0.31486,  Valid loss: 0.31134,  Valid R2: 0.81859,  Valid R: 0.93960, Time:  10m\n",
      "Epoch:  95,  Steps:    6080,  Train loss: 0.31337,  Valid loss: 0.29633,  Valid R2: 0.87795,  Valid R: 0.94172, Time:  11m, best!\n",
      "Epoch:  96,  Steps:    6144,  Train loss: 0.31319,  Valid loss: 0.30452,  Valid R2: 0.84370,  Valid R: 0.93672, Time:  12m\n",
      "Epoch:  97,  Steps:    6208,  Train loss: 0.31368,  Valid loss: 0.30553,  Valid R2: 0.81953,  Valid R: 0.93730, Time:  10m\n",
      "Epoch:  98,  Steps:    6272,  Train loss: 0.31230,  Valid loss: 0.30220,  Valid R2: 0.84454,  Valid R: 0.94073, Time:  10m\n",
      "Epoch:  99,  Steps:    6336,  Train loss: 0.31159,  Valid loss: 0.30923,  Valid R2: 0.81680,  Valid R: 0.93079, Time:  10m\n",
      "Epoch: 100,  Steps:    6400,  Train loss: 0.31170,  Valid loss: 0.31436,  Valid R2: 0.85293,  Valid R: 0.93278, Time:  10m\n",
      "Epoch: 101,  Steps:    6464,  Train loss: 0.31183,  Valid loss: 0.30179,  Valid R2: 0.82709,  Valid R: 0.93652, Time:  10m\n",
      "Epoch: 102,  Steps:    6528,  Train loss: 0.31151,  Valid loss: 0.30405,  Valid R2: 0.84821,  Valid R: 0.94126, Time:  10m\n",
      "Epoch: 103,  Steps:    6592,  Train loss: 0.31059,  Valid loss: 0.29519,  Valid R2: 0.86529,  Valid R: 0.93629, Time:  10m, best!\n",
      "Epoch: 104,  Steps:    6656,  Train loss: 0.31016,  Valid loss: 0.30617,  Valid R2: 0.82182,  Valid R: 0.93293, Time:  10m\n",
      "Epoch: 105,  Steps:    6720,  Train loss: 0.30955,  Valid loss: 0.30003,  Valid R2: 0.84548,  Valid R: 0.94496, Time:  10m\n",
      "Epoch: 106,  Steps:    6784,  Train loss: 0.30972,  Valid loss: 0.29573,  Valid R2: 0.86812,  Valid R: 0.94202, Time:  10m\n",
      "Epoch: 107,  Steps:    6848,  Train loss: 0.30831,  Valid loss: 0.31388,  Valid R2: 0.83392,  Valid R: 0.93603, Time:  10m\n",
      "Epoch: 108,  Steps:    6912,  Train loss: 0.30855,  Valid loss: 0.30838,  Valid R2: 0.82048,  Valid R: 0.93761, Time:  10m\n",
      "Epoch: 109,  Steps:    6976,  Train loss: 0.30860,  Valid loss: 0.31100,  Valid R2: 0.83325,  Valid R: 0.94055, Time:  10m\n",
      "Epoch: 110,  Steps:    7040,  Train loss: 0.30768,  Valid loss: 0.29672,  Valid R2: 0.82792,  Valid R: 0.94733, Time:  10m\n",
      "Epoch: 111,  Steps:    7104,  Train loss: 0.30696,  Valid loss: 0.30584,  Valid R2: 0.83576,  Valid R: 0.93576, Time:  10m\n",
      "Epoch: 112,  Steps:    7168,  Train loss: 0.30693,  Valid loss: 0.30082,  Valid R2: 0.85072,  Valid R: 0.94015, Time:  21m\n",
      "Epoch: 113,  Steps:    7232,  Train loss: 0.30647,  Valid loss: 0.30446,  Valid R2: 0.82942,  Valid R: 0.94153, Time:  95m\n",
      "Epoch: 114,  Steps:    7296,  Train loss: 0.30576,  Valid loss: 0.30603,  Valid R2: 0.81764,  Valid R: 0.94225, Time:  68m\n",
      "Epoch: 115,  Steps:    7360,  Train loss: 0.30590,  Valid loss: 0.31378,  Valid R2: 0.83771,  Valid R: 0.93891, Time:  97m\n",
      "Epoch: 116,  Steps:    7424,  Train loss: 0.30604,  Valid loss: 0.29934,  Valid R2: 0.82595,  Valid R: 0.93757, Time:  67m\n",
      "Epoch: 117,  Steps:    7488,  Train loss: 0.30492,  Valid loss: 0.29730,  Valid R2: 0.84846,  Valid R: 0.94125, Time:  67m\n",
      "Epoch: 118,  Steps:    7552,  Train loss: 0.30526,  Valid loss: 0.30087,  Valid R2: 0.82197,  Valid R: 0.94319, Time: 1.7h\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "! basenji_train.py --augment_rc --ensemble_rc --augment_shifts \"1,0,-1\" --logdir models/heart --params models/params_small.txt --train_data data/heart_l131k/tfrecords/train*.tfr --test_data data/heart_l131k/tfrecords/valid*.tfr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can just download a trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.isdir('models/heart'):\n",
    "    os.mkdir('models/heart')\n",
    "if not os.path.isfile('models/heart/model_best.tf.meta'):\n",
    "    subprocess.call('curl -o models/heart/model_best.tf.index https://storage.googleapis.com/basenji_tutorial_data/model_best.tf.index', shell=True)\n",
    "    subprocess.call('curl -o models/heart/model_best.tf.meta https://storage.googleapis.com/basenji_tutorial_data/model_best.tf.meta', shell=True)\n",
    "    subprocess.call('curl -o models/heart/model_best.tf.data-00000-of-00001 https://storage.googleapis.com/basenji_tutorial_data/model_best.tf.data-00000-of-00001', shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "models/heart/model_best.tf will now specify the name of your saved model to be provided to other programs.\n",
    "\n",
    "To further benchmark the accuracy (e.g. computing significant \"peak\" accuracy), use [basenji_test.py](https://github.com/calico/basenji/blob/master/bin/basenji_test.py).\n",
    "\n",
    "The most relevant options here are:\n",
    "\n",
    "| Option/Argument | Value | Note |\n",
    "|:---|:---|:---|\n",
    "| --rc | | Average the forward and reverse complement to form prediction. |\n",
    "| -o | output/heart_test | Output directory. |\n",
    "| --ai | 0,1,2 | Make accuracy scatter plots for targets 0, 1, and 2. |\n",
    "| --ti | 3,4,5 | Make BigWig tracks for targets 3, 4, and 5. |\n",
    "| -t | data/heart_l131k.bed | BED file describing sequence regions for BigWig track output. |\n",
    "| params_file | models/params_small.txt | Table of parameters to setup the model architecture and optimization. |\n",
    "| model_file | models/heart/model_best.tf | Trained saved model prefix. |\n",
    "| data_file | data/heart_l131k.h5 | HDF5 file containing the test input and output datasets as generated by [basenji_hdf5_single.py](https://github.com/calico/basenji/blob/master/bin/basenji_hdf5_single.py) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 4, 'batch_buffer': 4096, 'link': 'softplus', 'loss': 'poisson', 'optimizer': 'adam', 'adam_beta1': 0.97, 'adam_beta2': 0.98, 'learning_rate': 0.002, 'num_targets': 3, 'target_pool': 128, 'seq_length': 131072, 'target_length': 1024, 'cnn_dropout': 0.1, 'cnn_filter_sizes': [20, 7, 7, 7, 3, 3, 3, 3, 3, 3, 3, 1], 'cnn_filters': [128, 128, 192, 256, 256, 32, 32, 32, 32, 32, 32, 384], 'cnn_pool': [2, 4, 4, 4, 1, 0, 0, 0, 0, 0, 0, 0], 'cnn_dilation': [1, 1, 1, 1, 1, 2, 4, 8, 16, 32, 64, 1], 'cnn_dense': [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0]}\n",
      "Targets pooled by 128 to length 1024\n",
      "Convolution w/ 3 384x1 filters to final targets\n",
      "Targets pooled by 128 to length 1024\n",
      "Convolution w/ 3 384x1 filters to final targets\n",
      "2019-01-02 08:08:36.266670: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "WARNING:tensorflow:From /Users/davidkelley/code/Basenji/bin/basenji_test.py:132: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:`tf.train.start_queue_runners()` was called when no queue runners were defined. You can safely remove the call to this deprecated function.\n",
      "SeqNN test: 22479s\n",
      "Compute stats: 0s\n",
      "Test Loss:         0.42319\n",
      "Test R2:           0.26870\n",
      "Test PearsonR:     0.52756\n",
      "Test log PearsonR: 0.63650\n",
      "/Users/davidkelley/anaconda3/envs/py36/lib/python3.6/site-packages/scipy/stats/stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    }
   ],
   "source": [
    "! basenji_test.py --ai 0,1,2 -o output/heart_test --rc --shifts \"1,0,-1\" models/params_small.txt models/heart/model_best.tf data/heart_l131k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*data/heart_test/acc.txt* is a table specifiying the loss function value, R2, R2 after log2, and Spearman correlation for each dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0  0.32409  0.31190  0.56557  0.63816  aorta\n",
      "   1  0.19971  0.25741  0.51665  0.70792  artery\n",
      "   2  0.74578  0.23681  0.50046  0.56341  pulmonic_valve\n"
     ]
    }
   ],
   "source": [
    "! cat output/heart_test/acc.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The directories *pr*, *roc*, *violin*, and *scatter* in *data/heart_test* contain plots for the targets indexed by 0, 1, and 2 as specified by the --ai option above.\n",
    "\n",
    "E.g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"600\"\n",
       "            height=\"500\"\n",
       "            src=\"output/heart_test/pr/t0.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1059afda0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame('output/heart_test/pr/t0.pdf', width=600, height=500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
